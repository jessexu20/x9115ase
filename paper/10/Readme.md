## Reading Assignment 10

### Group Members:

- Zhe Yu (azhe825)[student ID: zyu9]

- Preetham Mahishi Srinath(preems)[student ID: pmahish]

- Shiqian Xu(jessexu20)[student ID: sxu11]

### Abstract
### Introduction
#### Feature Interaction Engineering
A software product line is a set of programs which share the same set of features and differ in few of them. A software is always customized as required by the stakeholder. The complexity of understanding the behavior of the software increases with the amount of customization it provides. Most of the programs provide a features where a user can tailor the program to the application scenario and customize it to his requirements. These customizable feature set is called user-selectable program. A feature interaction occurs when a combination of user-selected features has an unexpected influence of the performance of the program. Two or more features are involved in a feature interaction. It will also include features which are necessary for the features involved in the interaction to work. In the series of our paper reviews, we started from detecting feature interaction to analzying the performance of such feature interactions. The authors of the paper[2] aimed at detecting the dependencies and feature interactions in a software generated by the product line. They extended a the lightweight modeling language Alloy with support for feature oriented design and call the extension of Alloy as FeatureAlloy. They claim that the FeatureAlloy facilitates separation of concerns, variability, and reuse of models of individual features and helps detecting semantic dependences and feature interactions[2]. The authors of the paper[1] inteded to verify all the products of the software product line using product-line-verification techniques. The challange consisted of two parts, detecting feature interaction based on specifications without having the global system knowledge and detecting feature interactions without needing to generate all possible products of the product line. As the development in the feild of feature interaction engineering continued, new problems surfaced above. One of which is predicting the performance in the software when there is a feature interaction. The authors came up with a method that automatically detects performance feature interactions to improve prediction accuracy[3]. They propose three heuristics which reduces the number of measurements required to detect the feature interactions.

### Related Work
#### Feature Interaction Engineering
The two main techniques which were prevalant before were check the feature as far as possible in isolation[4] and check the entire product line in a single pass. These were as old as 2002 and are close to not possible with the modern software product lines. As the features become more and more complicated and closely tied to other features, the isolation becomes impossible. Also verifying the entire product line is challanging, as modern product lines offer too many options for specifications. Other model checking techniques have been proposed by considering variability of models in software product lines, especially state machines, into account and guarantee properties for all products that can be generated[5]. The problem with these is that too abstract for all facets of practical
software design[2].

The approaches for predicting performance in the case of feature interaction can be classified into two catagories namely model based and measurement based. Model based predictions are more common compared to measurement based. Linear and multiple regression
model the relationship between features and a performance output. Based on such a regression model, different estimation methods such as least squares and gradient descent can be used to predict the performance for input parameters. Bayesian networks are used to model the dependencies and probabilistic influence in a network of input parameters and performance. They help to learn the casual relationships between the parameters. These approaches can be used to find the correlation between the input parameters and the measurement output. Principle component analysis gives the direction of the maximal variance in a dataset. This can also be used in finding the PFIs. All of these techniques are very dependent on the scenarios being applied[3]. Measurement based approaches measures a configuration's properties based on the existing knowledge base consisting of measurements of already produced and measured configurations. They try to find the correlation between feature selection and the measurement. Also they do not provide any means to detect the PFIs.

### Results
#### Software Product Line Engineering
Software Product Line engineering, a set of software-intensive systems that share a common, managed set of features satisfying the specific needs of a particular market segment or mission and that are developed from a common set of core assets in a prescribed way.[ http://www.sei.cmu.edu/productlines/frame_report/what.is.a.PL.htm]. However, a scalable modelling and an efficient method to verify the system behavior needs to be put forward to meet the requirements. A featured transition system(FTS) has been purposed to obtain the behavior of each product of the Software product line. FTS is able to reason about the whole product line, or subsets of it, and model very detailed behavioral variations. Moreover, it could run model checking tool freely and take account into the feature dependencies and incompatibilities. Another model checking technique has been introduced to verify LTL properties for all the products of an SPL at once and would point out the products that violate the properties.  linear-time temporal logic is an infinite sequence of states where each point in time has a unique successor, based on a linear-time perspective. [http://www.cs.colostate.edu/~france/CS614/Slides/Ch5-Summary.pdf]
 Using SPL could help to take economic advantage of the fact that many of the products are very similar as planned and deliberate, strategic decisions are made to impact decisions systematically.

#### Model-checking technology - Product-Line Verification:
Model-checking technology is used to exhaustively and automatically check whether this model meets a given specification. Typically, one has hardware or software systems in mind, whereas the specification contains safety requirements such as the absence of deadlocks and similar critical states that can cause the system to crash. Model checking is a technique for automatically verifying correctness properties of finite-state systems and specifically product line verification is one type of model checking technology. In product line verification, there are three strategies which are product-based, sample-based and family based strategy. However, before [], there is no comparison between them in a controlled setting, therefore, [] provides case studies and experiments on that. And they have created an analytical model to describe the trade-offs of the individual verification strategies and given promising results after revisiting the discussion of the strengths and weaknesses of sample-based and family-based strategies, shown in figure, figure, figure. Furthermore, a generic conclusion is given that the success of a sample-based strategy depends on the defect and sample rates, whereas the success of the family-based strategy depends on the similarity between products. Also, sampling can save verification time but could lead to miss the defective products.

#### Scalable Analysis of Variable Software
Variability Analysis, known as family-based analysis, is not to generate and analysis variants separately but to directly analyze the variable code base by utilizing some configuration knowledge. Although, there are several proposals on this theme, there are no real-life, large-scale systems being implemented due to its potential challenges. It requires more effort than traditional analysis of a single system as all local variants are considered into the analysis. But the effort is worth taken as it could avoid analyzing the common code by taking advantage of similarities among variants. Therefore, [] proposed a way to detect whether variability-aware analysis scales to large systems, as it should consider all code and all variations of a system simultaneously. Before [], they have already come out with a sort of Java libraries which could handle the scaling in Java written project such as Featherweight Java, Lightweight Java, the lambda calculus, and other dialects of Java. They also took advantage of other researchers' variability-aware approaches for data-flow analysis using liveness analysis, which is a traditional data-flow analysis to compute whether variables are live, which may be read before being written again for a given statement. Its result can be used to conservatively detect dead code, useless code. A practical, scalable, variability-aware and sampling-based analysis for real-world, large-scale systems written in C is finally purposed. Experiments on large-scale system including Linux Kernel is taken and the performance of variability-aware analysis outperforms some of the sampling heuristics and still being complete and some of the limitations on pair-wise, sampling heuristics are found. Also some future work regarding to other large system should also be included to test the achieved results.
### Conclusion
### Improvement
### References
[1]  S. Apel, H. Speidel, P. Wendler, A. von Rhein, and D. Beyer, "Detection of feature interactions using feature-aware verification", in ASE. IEEE, 2011, pp. 372-375.

[2]  Apel, Sven, et al. "Detecting dependences and interactions in feature-oriented design." Software Reliability Engineering (ISSRE), 2010 IEEE 21st International Symposium on. IEEE, 2010.

[3]  Siegmund, Norbert, et al. "Predicting performance via automated feature-interaction detection." Proceedings of the 34th International Conference on Software Engineering. IEEE Press, 2012.

[4]  H. Li, S. Krishnamurthi, and K. Fisler. Verifying Cross-Cutting Features as Open Systems. In Proc. FSE, pages 89–98. ACM, 2002.

[5] A. Gruler, M. Leucker, and K. Scheidemann, “Calculating and Modeling Common Parts of Software Product Lines,” in Proc. Int. Software Product Line Conference (SPLC). IEEE CS, 2008, pp. 203–212.
